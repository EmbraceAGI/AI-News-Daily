

## 目的
本系列文章主要是用于持续跟踪最新的AI产业情况，让你减少知识焦虑。
## 看点
> 原文共计**113173** 字,简读后为**5496**字,阅读时间为14分钟,为您提高阅读效率为**2021%**


- 超厉害的人工智能助手来啦✨，帮助精算师们轻松工作！
- 手机设备公司当选啦！👍它将帮助NTT打造全球联网汽车项目。
- 用电脑命令行轻松调用Gemini模型💻️，简直太方便了！
- Cycode把会写代码的人工智能融入应用安全平台中，安全又智能！💪
- Finastra的Filogix推出神奇功能，用人工智能写贷款说明了✍️，又快又好！
- Twilio报告显示，CDP是人工智能获得客户洞察的重要基础。💡
- Amove和Storj让全球文件访问和远程协作变得超级简单！🌍
- 日立万塔任命艾曼·阿布埃勒法瓦为新任首席技术官，他是技术领域的佼佼者！🏆
- 谷歌的多模态人工智能Gemini，你必须知道的那些事！💡
- 诺基亚携手英伟达，用云RAN和人工智能变革移动网络📱！



## 从Gemini 1.5看大模型上下文技术的新发展！ 

  要点解析:

谷歌公司发布了突破性的大语言模型Gemini 1.5，该模型支持长达100万token的上下文长度，是目前业界领先水平。扩展大模型上下文长度的好处在于可以增强理解和连贯性、提升记忆和参考能力、处理复杂任务以及支持更长对话。然而，这一步也面临着计算资源需求增加、内存限制、梯度消失和爆炸、注意力机制局限性、数据稀疏性以及能效平衡等挑战。

研究者们也提出了多种扩展上下文长度的技术，包括RoPE、ALiBi、随机位置编码、xPos和LongNet。这些技术通过内插法和外推法，让大模型能够更有效地管理和利用大量数据，从而在多种任务中实现更精准的理解和生成。

 [https://juejin.cn/post/7337647568573595700](https://juejin.cn/post/7337647568573595700)

## 认识SPHINX-X：基于SPHINX开发的广泛多模态大语言模型系列！ 

 要点解析:

- SPHINX-X是建立在SPHINX框架之上的先进多模态大语言模型（MLLM）系列，通过改进架构、训练效率和数据集丰富，SPHINX-X在多模态任务上表现出比原始模型更优越的性能和泛化能力。

- SPHINX-X由上海人工智能实验室、MMLab、CUHK、罗格斯大学和加州大学洛杉矶分校的研究人员合作开发，其增强功能包括通过去除冗余视觉编码器来简化架构、使用跳过标记优化完全填充子图像的训练效率，以及过渡到单阶段训练范例。

- SPHINX-X利用了多样化的多模态数据集，并用精心策划的OCR和标记数据集进行了扩充，并在各种基础LLM上进行了训练，提供了一系列参数大小和多语言能力。

 [https://www.marktechpost.com/?p=52739](https://www.marktechpost.com/?p=52739)

## 揭秘SuperCLUE-Safety：为中文大模型量身打造的安全新框架！ 

  要点解析:

为了促进中文大模型的安全性，提出了一种新的多轮对抗性安全框架——SuperCLUE-Safety。该框架具有三个特点：

* 融合对抗性技术，具有较高的挑战性。

* 多轮交互下安全能力测试，更接近真实场景。

* 全面衡量大模型安全防护能力，包括传统安全类、负责任人工智能和指令攻击。

SuperCLUE-Safety评估模型在传统安全、负责任人工智能和指令攻击等三大能力的20多个子维度上的表现，为模型的安全水平提供全面测评。

 [https://juejin.cn/post/7337869843915931683](https://juejin.cn/post/7337869843915931683)

## 诺基亚携手英伟达，用云RAN和人工智能变革移动网络📱！ 

 要点解析:

诺基亚宣布与 NVIDIA 合作，旨在彻底改变未来人工智能就绪的无线电接入网络 (RAN) 解决方案。此次合作旨在将人工智能定位为转型的基础，以推动电信网络业务的未来发展。人工智能有望改变移动运营商领域的电信基础设施和服务格局，双方此次合作旨在通过引入创新型电信人工智能服务，为终端用户提供增值服务。

诺基亚在云 RAN 解决方案上与 NVIDIA 展开合作，将利用 NVIDIA Grace™ CPU 超级芯片进行第 2 层以上处理，诺基亚高性能、节能的 In-Line 第 1 层 (L1) 加速器技术和云 RAN 软件。此外，诺基亚还将在人工智能应用程序和 vRAN 加速中使用 NVIDIA GPU，从而为人工智能 RAN 铺平道路。

诺基亚客户可以选择多样化的产品，在云 RAN 网络中选择合适的 CPU。此项声明是诺基亚灵活的 anyRAN 方法的延续，该方法支持任何专门构建的、混合的或云 RAN 环境。它旨在帮助客户更快地启动和运行云 RAN 服务，消除复杂性并确保开放性和灵活性。诺基亚高性能、节能的 In-Line 加速架构可与所有领先的云或服务器基础设施无缝集成。诺基亚已与多家合作伙伴在多供应商设置中成功执行端到端 5G 数据呼叫（第 3 层呼叫）。

 [https://aithority.com/?p=564831](https://aithority.com/?p=564831)

## 独家揭秘！目前唯一可以使用Sora的官方渠道！ 

  要点解析:

近日，OpenAI对外宣布其AI模型Sora的使用已正式开放，但仅针对两类人群：OpenAI Red Teaming Network成员和视觉艺术家、设计师、电影制作者。前者需通过严格审核，后者条件模糊，目前尚未提供申请渠道。

OpenAI Red Teaming Network是一个由OpenAI发起的项目，旨在通过红队测试的方式评估和改进其AI模型，确保其安全性和可靠性。该网络欢迎来自不同背景和专业领域的人士加入，只要他们拥有提高AI安全性的热情。

申请加入OpenAI Red Teaming Network的方式很简单，只需填写官方表格即可，但审核难度较高，仅会对符合资格者开放使用Sora的机会。

 [https://juejin.cn/post/7337668768678297611](https://juejin.cn/post/7337668768678297611)

## Sora入门指南，4000字带你了解Sora！还附赠变现思路分析，让你玩转人工智能！ 

  要点解析:

- 近日，OpenAI推出文生视频模型SORA，该模型能够生成一分钟长的连续视频，且具有高质量的画面，这使得SORA在文生视频领域取得了突破性进展。目前，SORA已接入180个腾讯内部业务，包括腾讯会议、腾讯文档和微信搜一搜等，未来将有望在更多领域得到应用。

- SORA的原理主要涉及视觉数据表示、视频压缩网络、时空潜在表示以及Transformer模型。SORA采用patch概念对视频数据进行表示，并通过视频压缩网络降低数据的维度。同时，SORA利用时空潜在表示和Transformer模型进行视频生成，从而实现了一分钟长的高质量视频合成。

- 除了技术原理上的创新，SORA还具有以下优势：1）生成视频的长度远超其他文生视频模型；2）生成视频的质量更高，画面连贯且物体特征稳定；3）SORA的应用场景丰富，除了娱乐领域，还可用于教育、医疗等多个行业。

 [https://juejin.cn/post/7337517508152115235](https://juejin.cn/post/7337517508152115235)

## 最新揭秘！Sora到底是什么？一篇文章带你全面了解Sora！ 

  要点解析:

- 2月18日，OpenAI发布Sora，这是一个革命性的视频生成大型模型，凭借着视频质量、清晰度和文本语义还原能力，标志着该领域新时代的开启。Sora可以生成长达一分钟的视频，精准展现场景中的物理关系和物体间的遮挡碰撞，并且镜头效果流畅多变。

- 目前，Sora仅向特定测试团体开放，尚未与公众广泛使用的工具融合。但OpenAI已经开发了工具来检测误导性内容，并与红队研究员、视觉艺术家等专业人士合作，评估Sora的危害，提供创意反馈，推动模型发展。

- 未来，Sora可能会推动视频行业向着更高端、更创新的方向发展，但其对视频剪辑师、后期制作人员等传统岗位的影响还有待观察。OpenAI计划与政策制定者、教育工作者和艺术家合作，探索技术积极应用场景，平衡创新与责任。

 [https://juejin.cn/post/7337518755919282211](https://juejin.cn/post/7337518755919282211)

## 手把手教你用coze创造人工智能小说人物，写出精彩故事！ 

 要点解析:

- 字节跳动旗下的Coze.ai近期推出“角色扮演式” AI对话产品，用户能创建不同的小说人物角色并与之对话，还原度、逻辑性和趣味性备受好评。以《三体》中的程心为例，用户通过提供小说文本，使用Coze.ai的知识库构建功能，并利用提供的优化功能完善提示词，即可生成贴合程心性格和行为特点的AI角色。

- Coze.ai提供强大的插件功能，用户可添加开场白和默认问题，丰富对话内容。此外，Coze.ai还支持将对话角色发布到飞书、微信等平台，方便用户在不同场景中与AI角色互动。

- Coze.ai在处理小说文本时，推荐使用txt格式，并通过Python脚本去除空格和换行符进行数据处理。如果文档内容过大，建议将其分段后逐一处理，再通过知识库构建功能添加。

 [https://juejin.cn/post/7337877827727966242](https://juejin.cn/post/7337877827727966242)

## 玩转langchain chatchat，这些配置必看！ 

  要点解析:

**配置项1：向量引擎配置**

Langchain Chatchat 使用各种嵌入模型来生成文本的向量表示，这些模型可以用于文本分析、推荐系统和搜索引擎等应用。

**配置项2：生成式语言模型配置**

Langchain Chatchat 集成了多种大型语言模型（LLM），这些模型能够生成类似人类的文本，并用于构建聊天机器人、文本生成和自然语言理解应用程序。

**配置项3：重排序配置**

Langchain Chatchat 使用 BAAI 研究所开发的 reranker 模型来对文本序列进行重排序，以提高自然语言处理任务的性能，例如机器翻译、文本摘要和问答系统。

 [https://juejin.cn/post/7337630368906788902](https://juejin.cn/post/7337630368906788902)

## 谷歌的Gemma，因为谷歌还没想好要公开Gemini。 

  要点解析:

Google 开源了 Gemma 2B 和 7B 模型，这是一对较小型的 AI 模型，方便开发者更自由地使用其 Gemini 模型背后的研究成果。Gemma 模型体积小巧，能运行在开发者的笔记本电脑或台式机上，但据 Google 声称，它们在关键基准测试中“超越了显着更大规模的模型”。目前，这些模型可通过 Kaggle、Hugging Face、NVIDIA 的 NeMo 和 Google 的 Vertex AI 获得。

值得注意的是，Google 采用了与发布 Gemini 时截然不同的方式来对待 Gemma 的开源发布。开发者可以基于 Gemini 进行开发，但需要通过 API 或在 Google 的 Vertex AI 平台上进行。因此，Gemini 被认为是一个封闭的 AI 模型。通过使 Gemma 开源，更多的人可以试验 Google 的 AI，而不是转向提供更好访问权限的竞争对手。

 [https://www.theverge.com/2024/2/21/24078610/google-gemma-gemini-small-ai-model-open-source](https://www.theverge.com/2024/2/21/24078610/google-gemma-gemini-small-ai-model-open-source)

## 用coze扣子搭建人工智能绩效教练，管理者再也不用为绩效打分发愁了！ 

 要点解析:

- coze是一个国内可用的GPTs，可以帮助不懂代码的人快速构建一个AI应用，目前已接入180个腾讯内部业务。

- AI应用的最佳途径是B端产品，特别是办公领域的B端产品，因为在这个领域中有大量需要处理的数据，AI可以发挥优势，帮助员工和管理者提高效率。

- coze支持用自然语言来补充人设与回复内容，然后利用AI修改润色成格式更标准和完善的内容。

 [https://juejin.cn/post/7337865297849860147](https://juejin.cn/post/7337865297849860147)

## OpenAI视频生成模型Sora大解析，带你从头到尾了解它！ 

  要点解析:

- OpenAI发布的新型大模型Sora，具备生成视频的能力，标志着视频生成领域迈入大规模应用前夕。Sora通过三大Transformer组件，包括视觉编码器、softmax transformer和Transformer解码器，实现了视频生成。时空编码技术使Sora能够兼容不同分辨率、持续时间和长宽比的视频和图像。

- 基于DALLE 3的重字幕技术，Sora生成视频的文字描述更为详细准确。借鉴Google的W.A.L.T工作，引入自回归任务，提升了Sora对视频特征和图像间关系的学习能力。

- Sora的应用场景广泛，可用于影视制作、社交媒体内容生成和教育培训等领域。其强大的视频生成能力为视频行业和人工智能领域带来了新的发展机遇。

 [https://juejin.cn/post/7337942542023933987](https://juejin.cn/post/7337942542023933987)

## 人工智能实战2：3分钟搞定视频双语字幕！字幕组们欢呼吧🎉 

 要点解析:

利用大模型和翻译技术，为视频生成字幕。

主要步骤：利用剪映提取音轨字幕文件，使用国内大模型「kimi」翻译字幕，并通过剪映将翻译后的字幕添加到视频中。

用户遇到的痛点：视频没有字幕、英语讲解、不会视频编辑。解决方法：使用 AI 技术自动生成字幕，简化了操作流程。

 [https://juejin.cn/post/7337898389450178610](https://juejin.cn/post/7337898389450178610)

## 大语言模型推理加速第5弹：mlc-llm教程，把qwen-7b部署到手机上！ 

  要点解析:

- MLC-LLM：高性能通用部署解决方案

MLC-LLM 是一种高性能通用部署解决方案，允许使用具有编译器加速功能的本机 API 来本机部署任何大型语言模型。MLC-LLM 的使命是让每个人都能利用机器学习编译技术在每个人的设备上本地开发；优化和部署人工智能模型。

- 模型转换

MLC-LLM 提供了一个两步的模型转换过程来将大型语言模型转换为 MLC 格式：

1. 转换模型权重

2. 生成 MLC-LLM 配置

- 模型部署

转换后的模型可以通过 MLC-LLM 运行时部署和使用，从而实现高效的模型执行和推理。MLC-LLM 可以在各种设备上部署，包括台式机、服务器和移动设备，使其成为部署大型语言模型进行各种应用程序的理想解决方案。

 [https://juejin.cn/post/7337513012394590247](https://juejin.cn/post/7337513012394590247)

## 论文精华：如何解决个性化推荐数据稀疏性？用长尾增强的图对比学习算法！ 

  要点解析:

LAGCL是一种新的长尾增强图对比学习方法，它通过自适应采样和知识迁移模块来增强尾部节点的表示，通过对比学习来确保不同视图的相同节点表示更接近，不同节点表示更不同。LAGCL在三个公开数据集上的实验结果表明，它优于现有的基于图的对比学习方法，并在尾部节点上具有更好的性能增益。

LAGCL通过自适应采样模块为头部节点生成伪尾部节点，通过知识迁移模块利用伪尾部节点的已知邻域缺失信息来训练如何为真实尾部节点预测其真实的邻域缺失信息，从而增强尾部节点的表示。对比学习模块利用特征扰动的数据增强策略，最大化相同节点的表示一致性，最小化不同节点之间的表示相似性。

在消融实验中，LAGCL的每个子模块都表现出有效性，其中知识迁移模块的作用最大。自适应采样能够捕获到节点与其邻居之间通过随机采样所学习不到的迁移模式。生成对抗网络确保自适应采样产出的伪尾部节点更像真实尾部节点，保证了LAGCL整个训练框架的有效性。

 [https://juejin.cn/post/7337597892402249739](https://juejin.cn/post/7337597892402249739)

## 用图片识别图片，超简单！还附带了测试代码，让你轻松上手！ 

  要点解析:

- 实现以图识图功能的前提是拥有图片特征提取的方法和图片特征数据库，前者使用TensorFlow，后者使用Milvus。流程图清晰呈现了实现步骤，测试代码展示了特征向量的提取保存和查询过程。

- 使用ResNet50模型提取图像特征，重塑特征数组便于下游任务兼容。在Milvus中创建包含主键和特征向量的集合模式，第一次运行代码时创建字段，后续运行时可直接获取集合。

- 查询特征向量使用L2距离度量和Nprobe参数，返回最相似的图像。

 [https://juejin.cn/post/7337668768679591947](https://juejin.cn/post/7337668768679591947)

## 人工智能Agent的规划能力大揭秘，它是怎么思考和行动的？ 

  要点解析:

智能体规划模块的核心要素包括**长短期规划策略**，**规划输出格式**，**反馈与迭代机制**和**用户任务扩展解释优化**等。

智能体的短期规划注重于实时反馈，强调当前环境和自身状态的影响。长期规划则需要在行动开始前制定详细的步骤清单，考虑宏观目标和各种因素。一些智能体项目使用“专家招募”方法，通过挑选合适的工具提高适应性。而另一些项目则采用一次性全面分解宏观目标的方法。

长期规划和短期规划可以结合使用，在宏观目标的达成上使用长期规划方式，在局部任务的解决中使用短期规划能力。这样可以保证智能体的目标连贯性和方向性，同时也能响应即时的情况和挑战。

 [https://juejin.cn/post/7337870538138599439](https://juejin.cn/post/7337870538138599439)

## 人工智能实战1：用大模型分析情感！体验人工智能的强大魔力！ 

  要点解析:

在人工智能技术,特别是大模型的推动下,情感分析已经成为理解和分析文本数据中情感维度的一项强大技术.大模型,如Transformer架构的BERT和GPT系列,通过预训练和转移学习,捕捉语言的深层次结构,在情感分析任务中表现出色.情感分析的工作原理包括文本预处理;情感识别机制;自注意力机制和结果输出.

情感分析在实际应用中发挥着至关重要的作用,包括产品开发;营销策略;客户关系管理;客户服务自动化;健康保健和金融市场分析.它使企业能够深入理解市场和客户,做出更明智的商业决策,并持续优化产品和服务.

 [https://juejin.cn/post/7337586144433242146](https://juejin.cn/post/7337586144433242146)

## 深度强化学习算法附录3：蒙特卡洛方法和时序差分，揭开算法背后的奥秘！ 

 要点解析:

时序差分(TD)算法是强化学习(RL)中一种重要的无模型方法，它通过估计值函数或动作价值函数来学习最优策略。TD算法主要包括蒙特卡洛(MC)方法和时序差分(TD)算法。

MC方法通过对完整的序列进行取样来估计值函数或动作价值函数，而TD算法则通过利用当前时间步的估计值和下一个时间步的目标值来更新当前估计值。常见的TD算法包括Sarsa (on-policy)和Q-learning (off-policy)算法。Sarsa算法通过使用当前策略对下一个动作进行采样并利用目标值更新当前动作价值函数，而Q-learning算法则通过使用最优策略对下一个动作进行采样并利用目标值更新当前动作价值函数。

TD算法的优点在于它无需等待完整的序列，可以实时更新估计值，从而提高学习效率。同时，TD算法不需要模型信息，这使其适用于没有模型可用或模型复杂度较高的环境。

 [https://juejin.cn/post/7337573189516296232](https://juejin.cn/post/7337573189516296232)

## 论文解读：transformer在小目标检测上的表现如何？👀 

  要点解析:

- transformer在计算机视觉领域快速普及，在目标识别和检测领域表现突出，尤其是小目标检测（SOD）中，transformer始终优于基于CNN的检测器。

- 本文研究了transformer在SOD中的性能优势，将transformer的成功归因于其对输入图像中对象之间相互作用的建模、对高分辨率特征图的快速关注以及transformer本身完全基于注意力的特性。

- 作者通过分类、数据集展示和性能对比，全方位分析了影响transformer在SOD中的性能的因素，为进一步提高SOD transformer的性能提供了见解。

 [https://juejin.cn/post/7337853478113443877](https://juejin.cn/post/7337853478113443877)

## 在人工智能盛行的时代，纽扣还有用武之地吗？🤔 

  要点解析:

Sora文本转视频的AGI的出现标志着人工智能在理解真实世界场景并与之互动方面迈出了重大的一步，或成为实现通用人工智能的重要里程碑。它对模拟物理世界的逼真程度，达到了空前的高度，是之前人工智能技术从来没有做到过的。

扣子的AI Bot开发流程友好，符合其宣传，可以创建Bot、使用工作流、插件和知识库来让模型更准确地回答出你想要的答案。

国内的通用大模型与国外的通用大模型差距还是很大，通用人工智能就更不用说。Altman带领着openai向这个世界证明了AI时代已经到来，而国内所谓的“人工智能之父”李一舟还在卖课薅羊毛，不禁让人唏嘘。

 [https://juejin.cn/post/7337865297851072563](https://juejin.cn/post/7337865297851072563)

## 人工智能误导游戏：大语言模型的危险幻觉！小心不要被骗了！ 

  要点解析:

- 大型语言模型(LLM)虽有强大语言能力，却存在"幻觉"现象，即生成与来源内容或事实不符的信息，对相关领域应用造成挑战。幻觉分为输入冲突型、上下文冲突型和事实冲突型三类。

- 大模型产生幻觉的原因包括训练数据质量不佳、模型结构和解码算法偏差以及训练过程中不匹配等。解决幻觉问题的措施涉及数据和模型两个层面，主要包括诚实导向的监督微调、强化学习、改进推理策略、利用模型不确定性和知识检索等。

- 目前，研究机构已展开对大模型幻觉问题的探索，推出幻觉测试工具和排行榜，对不同LLM的幻觉程度进行评估，并针对降低幻觉风险提出建议，如改进模型设计、加强解释性和透明度等。

 [https://juejin.cn/post/7337928395610259490](https://juejin.cn/post/7337928395610259490)

## 最新资讯：Reddit赚大发了、人工智能搜索工具推荐、2024年大语言模型学习指南、人工智能教育报告 

  要点解析:

- 众多人工智能公司推出开发者激励计划，为开发者免费提供 tokens，鼓励开发者基于人工智能大模型进行开发。这标志着人工智能模型生态化进程加速，开发者活力和创新潜力将进一步释放。

- Reddit 与人工智能公司合作，授权后者访问其用户生成的内容，为人工智能大模型的训练和开发提供海量数据，标志着人工智能与互联网社交平台的深度融合。

- 秘塔 AI 搜索凭借其贴心的使用体验设计和完备的搜索来源，在人工智能增强搜索工具中脱颖而出，为用户提供更优质的信息获取体验。

 [https://juejin.cn/post/7337647568573808692](https://juejin.cn/post/7337647568573808692)

