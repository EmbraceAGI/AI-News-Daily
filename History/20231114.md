

## 目的
本系列文章主要是用于持续跟踪最新的AI产业情况，让你减少知识焦虑。
## 看点
> 原文共计**217195** 字,简读后为**20233**字,阅读时间为51分钟,为您提高阅读效率为**1065%**


- 1113早早聊AI资讯：定制GPT大爆发，一分钟一个GPT，H100再破纪录，4分钟训完GPT-3，Runway新功能再次惊艳AI圈 😱🚀
- 新的Nvidia超级计算芯片将‘推动AI的加速’ 🚀
- Luzia – 通过WhatsApp访问的AI助手 📱🤖
- “开源大模型新王者”：不是Meta的Llama 2，来自这家欧洲公司 🌐🏆
- 科技昨夜今晨1114：消息称苹果公司将禁止摇一摇跳转广告；英伟达发布新一代AI处理器H200性能最高提升90%；vivo X100系列手机发布，3999元起 📅📱💻
- 浙大拿下唯一最佳论文奖，中国团队喜获三项大奖！ACM MultiMedia 2023奖项揭幕 🏆🌐
- 谷歌起诉散布恶意软件的骗子，冒充其Bard AI聊天机器人 ⚖️🤖
- 生成式AI如何定义身份访问管理的未来 🔄🔐
- 用AI彻底改变Playwright测试 🔄💻
- OpenAI宣布改进的模型和API 🚀🔄



## 产业资讯

### AI艺术字比赛，OpenAI GPTs分享网站，AI项目坟场，农村程序员与独立开发者，小红书·大模型与推荐系统：ShowMeAI日报 

>要点解析:

 1. **GitHub Universe 2023**:

  - GitHub举办的年度技术大会，聚焦AI、安全和开发者体验。

  - 新推出的功能包括GitHub Copilot Chat、GitHub Copilot Enterprise、GitHub Copilot Partner Program等。

  - GitHub Advanced Security增加代码扫描自动修复和AI秘密扫描功能。

  - GitHub Copilot Workspace将在2024年发布，基于自然语言助手提高开发效率。

 

 2. **AI坟场**:

  - 记录近200个已停止运营的AI工具和服务，用户可投票并了解项目背景和技术实现。

  - 引发讨论，展示AI产品生命周期，向曾经闪耀的AI产品致敬。

 

 3. **Humane发布AI Pin**:

  - Humane推出全球首个可穿戴AI智能硬件产品AI Pin。

  - 小巧设备通过语音和手势进行交互，完成多项任务，包括日程管理、信息搜索、语音助手等。

  - 展示未来感的科技产品，引发期待。

 

 4. **工作流程图**:

  - 展示公司将代码部署到生产环境的典型工作流。

  - 从创建用户故事到代码提交、构建、测试、部署，最终监控生产环境的全过程。

 

 5. **农村程序员&独立开发者**:

  - 以访谈形式呈现农村程序员陈随易的生活哲学和经验。

  - 探讨获客渠道、应对收入不稳定焦虑、实现自由的心路历程。

  - 提供对想成为自由职业者的建议，包括保持好奇心、保持勇气等。

 

 6. **CNCC 2023 | 大模型与推荐系统**:

  - 小红书技术REDtech直播了大模型与推荐系统线下论坛。

  - 嘉宾分享大模型时代推荐系统的挑战与机会，以及大语言模型在推荐系统中的应用。

 

 

 >AI:GitHub领先AI开发者平台。AI坟场敬意曾闪耀AI工具。Humane创新AI Pin，颠覆未来。工作流程图揭示生产环境代码部署。农村程序员建议保持好奇与勇气。CNCC 2023挖掘大模型与推荐系统。 

原文链接:[https://juejin.cn/post/7300601948918792246](https://juejin.cn/post/7300601948918792246)

### 老黄深夜炸场，世界最强AI芯片H200震撼发布！性能飙升90%，Llama 2推理速度翻倍，大批超算中心来袭 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E8%80%81%E9%BB%84%E6%B7%B1%E5%A4%9C%E7%82%B8%E5%9C%BA%EF%BC%8C%E4%B8%96%E7%95%8C%E6%9C%80%E5%BC%BAAI%E8%8A%AF%E7%89%87H200%E9%9C%87%E6%92%BC%E5%8F%91%E5%B8%83%EF%BC%81%E6%80%A7%E8%83%BD%E9%A3%99%E5%8D%8790%25%EF%BC%8CLlama%202%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6%E7%BF%BB%E5%80%8D%EF%BC%8C%E5%A4%A7%E6%89%B9%E8%B6%85%E7%AE%97%E4%B8%AD%E5%BF%83%E6%9D%A5%E8%A2%AD](http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E8%80%81%E9%BB%84%E6%B7%B1%E5%A4%9C%E7%82%B8%E5%9C%BA%EF%BC%8C%E4%B8%96%E7%95%8C%E6%9C%80%E5%BC%BAAI%E8%8A%AF%E7%89%87H200%E9%9C%87%E6%92%BC%E5%8F%91%E5%B8%83%EF%BC%81%E6%80%A7%E8%83%BD%E9%A3%99%E5%8D%8790%25%EF%BC%8CLlama%202%E6%8E%A8%E7%90%86%E9%80%9F%E5%BA%A6%E7%BF%BB%E5%80%8D%EF%BC%8C%E5%A4%A7%E6%89%B9%E8%B6%85%E7%AE%97%E4%B8%AD%E5%BF%83%E6%9D%A5%E8%A2%AD)

### 谷歌起诉散布恶意软件的骗子，冒充其Bard AI聊天机器人 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://mashable.com/article/bard-ai-malware-scam-google-lawsuit](https://mashable.com/article/bard-ai-malware-scam-google-lawsuit)

### 配置即代码1737.v652ee9b_a_e0d9 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://plugins.jenkins.io/configuration-as-code/](https://plugins.jenkins.io/configuration-as-code/)

### 浙大拿下唯一最佳论文奖，中国团队喜获三项大奖！ACM MultiMedia 2023奖项揭幕 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E6%B5%99%E5%A4%A7%E6%8B%BF%E4%B8%8B%E5%94%AF%E4%B8%80%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%E5%A5%96%EF%BC%8C%E4%B8%AD%E5%9B%BD%E5%9B%A2%E9%98%9F%E5%96%9C%E8%8E%B7%E4%B8%89%E9%A1%B9%E5%A4%A7%E5%A5%96%EF%BC%81ACM%20MultiMedia%202023%E5%A5%96%E9%A1%B9%E6%8F%AD%E5%B9%95](http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E6%B5%99%E5%A4%A7%E6%8B%BF%E4%B8%8B%E5%94%AF%E4%B8%80%E6%9C%80%E4%BD%B3%E8%AE%BA%E6%96%87%E5%A5%96%EF%BC%8C%E4%B8%AD%E5%9B%BD%E5%9B%A2%E9%98%9F%E5%96%9C%E8%8E%B7%E4%B8%89%E9%A1%B9%E5%A4%A7%E5%A5%96%EF%BC%81ACM%20MultiMedia%202023%E5%A5%96%E9%A1%B9%E6%8F%AD%E5%B9%95)

### 谷歌采取法律行动打击使用虚假Bard广告传播恶意软件的骗子 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://siliconangle.com/?p=637166](https://siliconangle.com/?p=637166)

### 终结扩散模型，IGN单步生成逼真图像！UC伯克利谷歌革新LLM，美剧成灵感来源 

>要点解析:

 1. 生成式AI模型的演进：传统模型如GAN和扩散模型需要多步迭代生成图像，而幂等生成网络(IGN)通过单步即可生成逼真图像，标志着生成模型的新范式。

 2. 幂等生成网络(IGN)原理：

  - IGN是一个自对抗模型，无需独立的生成器和判别器，一步完成生成和判别。

  - 不同于扩散模型，IGN在单个步骤中将输入映射到目标数据分布，实现全局映射器的效果。

 3. 训练IGN的方法：

  - IGN被训练为将给定输入样本从源分布映射到目标分布，通过学习将映射到自身的实例流来实现。

  - 训练过程中，IGN将输入映射到目标数据分布，生成一致的、逼真的图像。

 4. 实验结果：

  - 在MNIST和CelebA数据集上评估，IGN一次生成结果相干，再次应用可纠正细节问题。

  - IGN具有一致的潜在空间，能有效处理分布外映射，表现出色彩、结构上的优越性。

 5. 潜在空间操纵和分布外映射：

  - IGN展示了一致的潜在空间，通过操纵操作和对不同分布的输入进行映射验证其全局映射的潜力。

 

 

 >AI:生成模型新范式，IGN引领未来。简洁、高效，推动AI生成模型发展。 

原文链接:[http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E7%BB%88%E7%BB%93%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%EF%BC%8CIGN%E5%8D%95%E6%AD%A5%E7%94%9F%E6%88%90%E9%80%BC%E7%9C%9F%E5%9B%BE%E5%83%8F%EF%BC%81UC%E4%BC%AF%E5%85%8B%E5%88%A9%E8%B0%B7%E6%AD%8C%E9%9D%A9%E6%96%B0LLM%EF%BC%8C%E7%BE%8E%E5%89%A7%E6%88%90%E7%81%B5%E6%84%9F%E6%9D%A5%E6%BA%90](http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E7%BB%88%E7%BB%93%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%EF%BC%8CIGN%E5%8D%95%E6%AD%A5%E7%94%9F%E6%88%90%E9%80%BC%E7%9C%9F%E5%9B%BE%E5%83%8F%EF%BC%81UC%E4%BC%AF%E5%85%8B%E5%88%A9%E8%B0%B7%E6%AD%8C%E9%9D%A9%E6%96%B0LLM%EF%BC%8C%E7%BE%8E%E5%89%A7%E6%88%90%E7%81%B5%E6%84%9F%E6%9D%A5%E6%BA%90)

### 通过与用户互动改进在RAG用例中的LLM响应 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://aws.amazon.com/blogs/machine-learning/improve-llm-responses-in-rag-use-cases-by-interacting-with-the-user/](https://aws.amazon.com/blogs/machine-learning/improve-llm-responses-in-rag-use-cases-by-interacting-with-the-user/)

### 生成式AI如何定义身份访问管理的未来 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://venturebeat.com/security/how-generative-ai-is-defining-the-future-of-identity-access-management/](https://venturebeat.com/security/how-generative-ai-is-defining-the-future-of-identity-access-management/)

### 马斯克正式「切脑」，Neuralink内部实验室照片曝光！7年计划22000例手术，全力研发只为对抗超级AI 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E9%A9%AC%E6%96%AF%E5%85%8B%E6%AD%A3%E5%BC%8F%E3%80%8C%E5%88%87%E8%84%91%E3%80%8D%EF%BC%8CNeuralink%E5%86%85%E9%83%A8%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%85%A7%E7%89%87%E6%9B%9D%E5%85%89%EF%BC%817%E5%B9%B4%E8%AE%A1%E5%88%9222000%E4%BE%8B%E6%89%8B%E6%9C%AF%EF%BC%8C%E5%85%A8%E5%8A%9B%E7%A0%94%E5%8F%91%E5%8F%AA%E4%B8%BA%E5%AF%B9%E6%8A%97%E8%B6%85%E7%BA%A7AI](http://weixin.sogou.com/weixin?type=2&query=%E6%96%B0%E6%99%BA%E5%85%83+%E9%A9%AC%E6%96%AF%E5%85%8B%E6%AD%A3%E5%BC%8F%E3%80%8C%E5%88%87%E8%84%91%E3%80%8D%EF%BC%8CNeuralink%E5%86%85%E9%83%A8%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%85%A7%E7%89%87%E6%9B%9D%E5%85%89%EF%BC%817%E5%B9%B4%E8%AE%A1%E5%88%9222000%E4%BE%8B%E6%89%8B%E6%9C%AF%EF%BC%8C%E5%85%A8%E5%8A%9B%E7%A0%94%E5%8F%91%E5%8F%AA%E4%B8%BA%E5%AF%B9%E6%8A%97%E8%B6%85%E7%BA%A7AI)

### 热门AI平台推出奖励制度，鼓励制作真人深度伪造 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.engadget.com/popular-ai-platform-introduces-rewards-system-to-encourage-deepfakes-of-real-people-194326312.html?src=rss](https://www.engadget.com/popular-ai-platform-introduces-rewards-system-to-encourage-deepfakes-of-real-people-194326312.html?src=rss)

### 用AI彻底改变Playwright测试 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://hackernoon.com/revolutionizing-playwright-tests-with-ai?source=rss](https://hackernoon.com/revolutionizing-playwright-tests-with-ai?source=rss)

### OpenAI宣布改进的模型和API 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[http://www.i-programmer.info/news/105-artificial-intelligence/16751-openai-announces-improved-models-and-apis.html](http://www.i-programmer.info/news/105-artificial-intelligence/16751-openai-announces-improved-models-and-apis.html)

### 你很快就可以在OpenAI的无代码应用商店中构建自己的GPT 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://techround.co.uk/?p=91076](https://techround.co.uk/?p=91076)

### 谷歌起诉散布虚假、充满恶意软件的Bard聊天机器人下载的骗子 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.theregister.com/2023/11/14/google_sues_ai_scammer/](https://www.theregister.com/2023/11/14/google_sues_ai_scammer/)

### 最强大模型训练芯片H200发布！141G大内存，AI推理最高提升90% 

>要点解析:

 1. **H200芯片发布:** 英伟达推出了H200芯片，号称是世界上最强大的GPU，专为人工智能和超级计算而设计。新一代GPU具有141GB大内存，采用了HBM3e内存技术，内存带宽高达4.8TB/s，极大提升了AI处理性能。

 2. **性能提升:** H200在推理性能上几乎翻倍，运行GPT3-175B时性能提高60%。这对于AI公司意味着更高效的计算能力，为大规模模型的训练和推理提供了更强大的支持。

 3. **兼容性与升级:** H200与先前的H100完全兼容，使得将H200添加到已有系统中变得简便。这种设计考虑到了用户的升级需求，无需进行额外的系统调整即可享受新一代GPU的性能提升。

 4. **HGX H200平台:** 英伟达发布了HGX H200平台，将8块H200整合到一起，总显存高达1.1TB，适用于训练和推理大模型。该平台采用了高速互联技术，支持各种应用负载，展现了H200在超级计算领域的强大潜力。

 5. **Quad GH200超算节点:** 由4个GH200组成的Quad GH200超算节点提供了288 Arm CPU内核和2.3TB的高速内存。超算中心将使用这些节点构建庞大的超级计算机，为科学研究和计算密集型任务提供强大的计算支持。

 

 

 >AI:AI巨头再进化，英伟达发布H200，引领GPU性能革新。 

原文链接:[http://www.qbitai.com/?p=97868](http://www.qbitai.com/?p=97868)

### 新的芯片设计提升AI工作负载处理 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://aibusiness.com/ml/new-chip-designs-to-boost-ai-workload-processing](https://aibusiness.com/ml/new-chip-designs-to-boost-ai-workload-processing)

### 被动SSH服务器私钥妥协是真实的...对于一些易受攻击的设备 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.theregister.com/2023/11/14/passive_ssh_key_compromise/](https://www.theregister.com/2023/11/14/passive_ssh_key_compromise/)

### Palo Alto Networks将BYOML框架添加到Cortex XSIAM 2.0 - Help Net Security 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LmhlbHBuZXRzZWN1cml0eS5jb20vMjAyMy8xMS8xMy9wYWxvLWFsdG8tbmV0d29ya3MtY29ydGV4LXhzaWFtLTItMC_SAQA?oc=5](https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LmhlbHBuZXRzZWN1cml0eS5jb20vMjAyMy8xMS8xMy9wYWxvLWFsdG8tbmV0d29ya3MtY29ydGV4LXhzaWFtLTItMC_SAQA?oc=5)

### 使用Amazon Personalize实施实时个性化推荐 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://aws.amazon.com/blogs/machine-learning/implement-real-time-personalized-recommendations-using-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/implement-real-time-personalized-recommendations-using-amazon-personalize/)

### AI视频生成硬件：亲身体验第一台AI机器 

>要点解析:

 1. **1stAI Machine**：这是一款由AI生成的视频编辑设备，为用户提供了全新的创意工具。它采用Runway ML的软件，通过物理设备上的旋钮和按钮，用户可以控制不同的输入样式和处理效果。这标志着AI硬件的新时代，让视频编辑更加直观和创意。

 2. **硬件兴起**：与其他类似的AI硬件设备相比，如Humane推出的Ai Pin，1stAI Machine是一种突破性的视频编辑板。AI硬件迅速崛起，为创意和媒体制作领域带来了新的可能性。

 3. **创作者团队**：1stAI Machine由位于马德里的创意机构SpecialGuestX（SGX）的团队设计制作。这个小团队通过结合Runway的软件和自己的创意，打造了这款独特的AI生成设备。

 4. **工作流程**：1stAI Machine的工作流程包括故事板选择、风格调整和音乐选择。用户可以通过设备上的屏幕和旋钮，选择他们想要的输入样式、风格和背景音乐，从而生成独特的视频作品。

 5. **未来展望**：虽然目前1stAI Machine仅是一个原型，但它引发了对更先进模型的兴趣。未来版本可能支持用户上传自己的故事板和图像，甚至在大型活动中进行现场AI生成视频的体验。

 

 

 >AI:AI改变视频编辑游戏。 

原文链接:[https://venturebeat.com/ai/ai-video-generating-hardware-hands-on-with-the-1stai-machine/](https://venturebeat.com/ai/ai-video-generating-hardware-hands-on-with-the-1stai-machine/)

### 为全球AI监管制定路径 

>要点解析:

 1. **全球呼声：AI治理的迫切需求：** 随着人工智能（AI）在塑造我们生活的方方面面中发挥日益增长的作用，全球范围内对于严格监管框架的呼声此起彼伏。虽然技术显然具有巨大的经济增长和社会进步潜力，但同样存在尚未完全理解的风险。这种背景下，中国科学家呼吁强有力的监管，美国总统乔·拜登签署了一项雄心勃勃的行政命令，而一场AI安全峰会也即将召开，使全球在AI治理上的视角协调变得尤为关键。

 

 2. **平衡创新与安全的核心：** 拜登总统最近签署的行政命令触及了美国的核心理念：在创新与安全、伦理之间寻求平衡。该命令认识到AI的颠覆性能力，从推动癌症研究到潜在加深社会不平等，都是至关重要的第一步。它要求AI开发者与政府分享安全数据，并旨在为AI工具的公开发布设定标准。尤为值得赞赏的是，该命令涉及到隐私、公民权利和工人权益等广泛领域，然而，其方法更偏向技术行业内的自我管理，为未来更强有力的立法留下了空间。

 

 3. **中国的存在性警告：全球监管的呼声：** 相比之下，中国的AI专家公开表示，人工智能对人类构成了“存在性威胁”。尽管西方学术界常因描绘末日般的场景而受到批评，但中西方科学家之间的共识表明，对于未受监管的AI带来的风险存在着越来越多的全球共识。他们呼吁建立国际监管机构，强制注册，并将研究预算的大部分用于AI安全，这种呼声在中美技术竞争的更广泛背景下显得格外重要。

 

 4. **全球AI安全峰会：多元视角的交汇：** 即将在英国举行的AI安全峰会旨在汇集国际政治和科技领导人，为全球AI治理奠定基础。英国首相里希·苏纳克的起草公报表明了一种谨慎的态度，警告先进AI模型可能带来潜在危害，但没有提出具体的法规建议。峰会的参与者将在塑造AI的安全和公正部署方面发挥关键作用，他们的意见跨足加拿大到新加坡，将为共同构建AI治理愿景贡献力量。

 

 5. **前路：挑战与机遇：** 将这些不同但重要的对话联系在一起，很明显没有简单的答案。对AI治理的普遍性方法必须在地缘政治紧张局势、保护个人自由和确保安全而不扼杀创新之间找到平衡。实现这种平衡具有挑战性，但集体的情绪似乎更趋向于谨慎。这些讨论是否能够转化为具体的全球政策尚不明朗，但鉴于局势不断升级，采取协调行动的紧迫性前所未有。

 

 

 >AI:创新与安全，全球需共舞。 

原文链接:[https://hackernoon.com/navigating-the-complexities-of-global-ai-regulation?source=rss](https://hackernoon.com/navigating-the-complexities-of-global-ai-regulation?source=rss)

### 网络钓鱼骗子 - 数字世界的底层食物链 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://hackernoon.com/phishing-scammers-the-bottom-feeders-of-the-digital-world?source=rss](https://hackernoon.com/phishing-scammers-the-bottom-feeders-of-the-digital-world?source=rss)

### FTC为非银行金融机构采纳数据泄露通知义务 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[264131 at https://www.natlawreview.com/article/ftc-adopts-data-breach-notification-obligations-non-banking-financial-institutions](264131 at https://www.natlawreview.com/article/ftc-adopts-data-breach-notification-obligations-non-banking-financial-institutions)

### 生成式AI如何定义身份访问的未来... - VentureBeat 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vdmVudHVyZWJlYXQuY29tL3NlY3VyaXR5L2hvdy1nZW5lcmF0aXZlLWFpLWlzLWRlZmluaW5nLXRoZS1mdXR1cmUtb2YtaWRlbnRpdHktYWNjZXNzLW1hbmFnZW1lbnQv0gEA?oc=5](https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vdmVudHVyZWJlYXQuY29tL3NlY3VyaXR5L2hvdy1nZW5lcmF0aXZlLWFpLWlzLWRlZmluaW5nLXRoZS1mdXR1cmUtb2YtaWRlbnRpdHktYWNjZXNzLW1hbmFnZW1lbnQv0gEA?oc=5)

### 车辆很快将携带'护盾'四处行驶，抵御网络攻击 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://auto.economictimes.indiatimes.com/news/industry/vehicles-to-soon-drive-around-with-shields-to-fend-off-cyberattacks/105196508](https://auto.economictimes.indiatimes.com/news/industry/vehicles-to-soon-drive-around-with-shields-to-fend-off-cyberattacks/105196508)

### 中国工商银行支付赎金以阻止网络攻击干扰美国财政市场 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.techtimes.com/articles/298633/20231113/chinas-icbc-paid-ransom-stop-cyberattack.htm](https://www.techtimes.com/articles/298633/20231113/chinas-icbc-paid-ransom-stop-cyberattack.htm)

### 谷歌起诉使用Bard‘剥削’公众的骗子 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://feed.feedburster.com/techcrunch/android/redirect?url=https://www.androidcentral.com/apps-software/google-sues-bard-scammers](https://feed.feedburster.com/techcrunch/android/redirect?url=https://www.androidcentral.com/apps-software/google-sues-bard-scammers)

## 产品介绍

### 英伟达最新AI芯片H200或将成为其史上最赚钱产品之一 

>要点解析:

 1. **H200芯片发布：**

  - H200是英伟达推出的新一代人工智能芯片，针对各种AI模型进行训练和部署。

  - 作为H100芯片的升级版，H200配备了141GB的内存，特别擅长执行“推理”任务。

 

 2. **性能提升和特点：**

  - 在执行推理或生成问题答案时，H200相较于H100提升了60%至90%的性能。

  - H200采用了HBM3e内存，速度更快、容量更大，使其更适用于大型语言模型。

 

 3. **兼容性和发布计划：**

  - H200将与H100完全兼容，无需更改已有系统或软件即可适应。

  - 预计H200将于2024年第二季度上市，将与AMD的MI300X GPU展开竞争。

 

 4. **市场和需求：**

  - 大型模型的尺寸正在迅速扩大，H200应运而生，解决了训练生成式AI和高性能计算应用的需求。

  - H200的高成本和市场需求使得英伟达在芯片供应领域备受追捧，取得了巨大的成功。

 

 5. **行业趋势和影响：**

  - 观察市场动态，大型模型的需求不断增加，H200代表了行业领先的AI超级计算平台，推动技术创新。

 

 

 >AI:AI巨头英伟达的H200，将颠覆大型模型训练与推理，助力行业创新。 

原文链接:[https://m.cnbeta.com.tw/view/1396697.htm](https://m.cnbeta.com.tw/view/1396697.htm)

### 新的Nvidia超级计算芯片将‘推动AI的加速’ 

>要点解析:

 1. **Nvidia主导AI革命：** 2023年对Nvidia来说是突破性的一年，不仅在游戏或比特币挖矿方面取得成功，而且推动着AI革命向前迈进，不断刷新计算能力的新基准。

 2. **Hopper GPU芯片升级：** Nvidia的Hopper GPU芯片更新为Nvidia H200，提供了改进的性能，同时实现了成本和能源效率，加速工业设计和模拟，特别是在数据中心领域。

 3. **H200的特性：** Nvidia H200是第一款提供HBM3e的GPU，具有更快、更大的内存，用于推动生成式AI和大型语言模型的加速，同时推进科学计算的HPC工作负载。

 4. **Grace Hopper超级芯片：** Grace Hopper超级芯片将Nvidia的Grace和Hopper技术合并，驱动着戴尔和HPE等主要制造商构建的超级计算机。GH200用于研究和重型计算任务，提供了200艾克斯弗洛普的AI性能。

 5. **量子处理单元(QPUs)的发展：** Nvidia介绍了量子处理单元（QPUs）的发展，通过名为CUDA quantum的开放编程模型引领着未来超级计算机的发展，迈向量子加速超级计算时代。

 6. **CUDA quantum的应用：** CUDA quantum的整合使研究人员能够模拟量子处理器，而不仅仅是理论。例如，BASF的研究人员利用CUDA quantum开创了一种用于模拟化学催化剂的混合量子-经典方法，可保护人类免受有害金属的侵害。

 7. **Nvidia支持AI驱动业务：** 除了计算硬件，Nvidia指出它支持以AI为驱动力的企业，为初创公司和企业提供训练模型的硬件支持，如OpenAI和Stability AI等行业巨头。

 8. **股票表现和市值增长：** 2023年，Nvidia的股价增长近200％，巩固了其作为推动SP500的领先企业的地位，显示出该公司在众多AI业务背后的引擎作用。

 9. **Nvidia的未来：** 作为AI革命的先驱，Nvidia的未来不仅仅是写在代码中，更体现在其开创性芯片的硅中。

 

 

 >AI:AI革命引领者，Nvidia引爆2023！ 

原文链接:[https://decrypt.co/205899/new-nvidia-supercomputing-chips-to-fuel-the-acceleration-of-ai](https://decrypt.co/205899/new-nvidia-supercomputing-chips-to-fuel-the-acceleration-of-ai)

### Luzia – 通过WhatsApp访问的AI助手 

>要点解析:

 1. **Luzia AI简介：** Luzia是一款虚拟助手聊天机器人，可以直接通过WhatsApp和Telegram访问。它是由三位创始人在2021年创建，旨在通过用户熟悉的消息平台轻松普及人工智能。

 2. **主要功能：**

- **自然对话：** Luzia可以使用文本和语音进行自然对话，与用户进行日常话题的轻松聊天。

- **信息搜索：** 具有访问通用知识的能力，可以提供关于地点、事件、天气、体育等方面的有用信息。

- **翻译：** 提供文本翻译功能，支持多种语言，包括英语、西班牙语、法语等。

- **文字转语音：** 可以将音频剪辑和语音笔记转录为可读的文本。

- **图像生成：** 提供根据文本提示生成独特图像的功能，创造原创数字艺术品。

- **个人助手：** 可作为个人助手，协助提高生产力，进行日程安排、制定清单、提醒等任务。

- **健康支持：** Luzia Mind作为扩展功能提供AI生活辅导，包括情感支持、压力管理、正念练习、健康建议和每日动力。

- **无需额外应用：** Luzia直接在WhatsApp和Telegram中运行，无需下载额外的应用程序。

 

 3. **如何在WhatsApp上使用Luzia：**

  - 访问Luzia网站，点击“Try Now”。

  - 添加Luzia为联系人，之后Luzia将在WhatsApp中向您发送消息。

  - 开始聊天，通过文本、语音笔记、图像等方式与AI助手互动。

 

 4. **在WhatsApp上使用Luzia的好处：**

  - **覆盖范围：** 通过全球使用超过20亿人的应用程序，实现对AI助手的访问。

  - **便捷性：** 无需下载未知软件即可获得人工智能功能。

  - **熟悉性：** 在人们每天使用的界面中使用，提高用户熟悉度。

  - **隐私：** 无需提供个人信息即可匿名使用。

  - **可用性：** 通过WhatsApp随时随地准备好的AI助手。

  - **多语言支持：** 在相同平台上支持多种语言。

  - **免费：** 直接在WhatsApp中免费访问Luzia。

 

 5. **局限性和风险：**

  - 提供的信息可能不总是准确。

  - 图像生成能力可能被不道德地使用。

  - 隐私保护尚不明确。

  - 对话技能仍然有限。

  - 依赖互联网连接。

  - 可能存在欺诈/冒名顶替的风险。

 

 6. **Luzia和AI助手的未来：**

  - **无缝多应用集成：** 单一助手在各种聊天应用程序中可访问。

  - **通用翻译器：** 在对话过程中实现实时翻译。

  - **增强对话能力：** 自然而然地讨论更复杂的主题。

  - **个性化建议：** 根据用户偏好提供定制建议。

  - **增强创造力：** 将人类和AI的能力融合为创新。

 

 7. **结论：**

  - Luzia为用户提供了一个透过WhatsApp直接访问的实用AI助手，其自然语言处理、对话能力和多样化功能使其成为WhatsApp界面中备受欢迎的AI伴侣。

  - 随着技术的不断进步，将AI助手直接集成到消息应用程序中可能会在未来变得越来越普遍。

  - 尽管仍然存在一些限制，但Luzia代表了将AI的力量直接带给数十亿用户的早期里程碑。利用消息应用程序的覆盖范围提供AI的机会，使其更加可用、可访问和主流化。有关Luzia的任何问题吗？需要在AI工具或其他方面获得额外帮助吗？

  

 

 >AI:AI直达WhatsApp，Luzia点燃普通用户对未来的无限遐想！ 

原文链接:[https://openaimaster.com/?p=26581](https://openaimaster.com/?p=26581)

### 如何在WhatsApp中使用Luzia AI 

>要点解析:

 1. **Luzia的背景与创建：**

  Luzia是由Carlos Pérez等三位创始人于2023年创建的人工智能虚拟助手，旨在通过用户已经使用的消息应用程序，如WhatsApp，使人工智能变得更加普遍。

  

 2. **Luzia在WhatsApp中的激活步骤：**

  - 访问Luzia官方网站或将其添加为WhatsApp联系人。

  - 开始与Luzia的对话，它像普通的WhatsApp联系人一样运作。

  - 利用Luzia的功能，包括会话、图像生成、语音转录、文本翻译等。

 

 3. **Luzia的关键功能与能力：**

  - 会话：在许多日常主题上进行讨论。

  - 信息：回答问题或搜索有用信息。

  - 翻译：在不同语言之间翻译文本。

  - 语音转录：将音频转换为文本。

  - 图像生成：基于文本提示创建独特图像。

  - 个人助手：处理日程、列表、提醒等。

  - 健康支持：提供情感支持、健康提示和动力。

 

 4. **在WhatsApp上使用Luzia的优势：**

  - 超过20亿WhatsApp用户的庞大覆盖面。

  - 在现有WhatsApp界面内工作，无需额外应用。

  - 利用用户每天已经使用的应用程序。

  - 随时随地通过快速命令进行聊天。

  - 无需注册，全程加密，免费使用。

 

 5. **使用Luzia的限制：**

  - 回答可能不总是完全准确。

  - 会话能力仍然有限。

  - 图像生成可能被滥用。

  - 隐私保护和内容管理仍不明确。

  - 需要互联网连接才能运行。

 

 6. **AI助手的未来可能性：**

  - 跨多个流行聊天应用程序的无缝集成。

  - 更先进的自然语言对话能力。

  - 根据用户喜好提供上下文推荐。

  - 人工智能与人类协作增强创造力。

  - 实现即时语音翻译，实现全球无缝交流。

  - 预测性智能主动提供有用信息。

 

 7. **结论：**

  Luzia旨在通过提供功能齐全的虚拟助手直接在流行的WhatsApp消息应用程序中，使人工智能的使用普及化。尽管存在一些准确性、隐私和对话复杂性方面的限制，但Luzia为超过20亿WhatsApp用户提供了一种轻松享受人工智能功能的方式。

 

 

 >AI:AI轻松融入WhatsApp，Luzia为用户创造全新体验。 

原文链接:[https://openaimaster.com/?p=26586](https://openaimaster.com/?p=26586)

### AI初创公司「极睿科技」完成数千万美元B轮融资 

>要点解析:

 1. **极睿科技B轮融资:** 极睿科技最近完成了一轮数千万美元的B轮融资，投资方为顺为资本。这标志着该公司在人工智能领域的发展取得了新的进展。

 2. **前期融资:** 极睿科技成立于2017年，之前曾获得红杉资本、图灵创投的亿元级A轮融资，以及金沙江创投、魔量资本的数千万元Pre-A轮投资。

 3. **核心团队背景:** 公司核心团队成员来自清华大学计算机系人工智能国家重点实验室，拥有清华大学、美国麻省理工(MIT)、新加坡国立大学、人民大学等学校的教授顾问团队。

 4. **技术背景:** 极睿科技在人工智能领域有着深厚的技术背景，专注于开发创新的AI解决方案。

 5. **发展方向:** 通过完成B轮融资，极睿科技将有更多资金支持，有望加速技术研发，推动人工智能领域的创新发展。

 

 

 >AI:创新融资助力极睿科技领先AI领域。 

原文链接:[http://www.fromgeek.com/vc/612397.html](http://www.fromgeek.com/vc/612397.html)

## 技术教程

### 配置即代码1737.v652ee9b_a_e0d9 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://plugins.jenkins.io/configuration-as-code/](https://plugins.jenkins.io/configuration-as-code/)

### 用AI彻底改变Playwright测试 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://hackernoon.com/revolutionizing-playwright-tests-with-ai?source=rss](https://hackernoon.com/revolutionizing-playwright-tests-with-ai?source=rss)

### OpenAI宣布改进的模型和API 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[http://www.i-programmer.info/news/105-artificial-intelligence/16751-openai-announces-improved-models-and-apis.html](http://www.i-programmer.info/news/105-artificial-intelligence/16751-openai-announces-improved-models-and-apis.html)

### 你很快就可以在OpenAI的无代码应用商店中构建自己的GPT 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://techround.co.uk/?p=91076](https://techround.co.uk/?p=91076)

### 谷歌起诉散布虚假、充满恶意软件的Bard聊天机器人下载的骗子 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.theregister.com/2023/11/14/google_sues_ai_scammer/](https://www.theregister.com/2023/11/14/google_sues_ai_scammer/)

### GitLab的新AI功能赋能DevSecOps 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://www.artificialintelligence-news.com/?p=13876](https://www.artificialintelligence-news.com/?p=13876)

### 生成式AI如何定义身份访问管理的未来 

>要点解析:

 1. **ACM MultiMedia 2023中国团队崭露头角**: 在2023 ACM MultiMedia会议上，中国团队从902篇录用论文中脱颖而出，斩获最佳论文奖、荣誉提名奖和创新创意奖三项大奖。

 2. **论文成果概览**:

  - 最佳论文奖: 介绍了一种定位优化框架，通过解耦定位细化和动作检测，显著提升动作边界定位的精度。

  - 荣誉提名奖: 解决在不同人物手部模型间进行运动语义迁移的问题，提出基于解剖结构的语义矩阵，实现精确的手部运动重定向。

  - 创新创意奖: 提出了CATR框架，基于组合依赖和音频查询，实现音频引导的视频分割，为多模态交互提供深度融合。

 3. **任务背景与挑战**:

  - 传统动作检测中的定位问题。

  - 手部模型间的运动语义迁移。

  - 音频引导的视频分割中的难点。

 4. **解决方案与模型设计**:

  - 解耦的音视频交互编码器。

  - 组模块门控机制。

  - 基于音频查询的解码器。

 5. **实验结果**:

  - CATR模型在多源音频数据集上表现显著，为音频引导的视频分割应用提供更多可能性。

 6. **主要作者介绍**:

  - 李可欣：浙江大学博士生，研究方向为跨媒体视频理解和交互式视频分割。

  - 杨宗鑫：浙江大学计算机学院博士后研究员，专注于视频理解、视觉内容生成和三维视觉等。

  - 杨易教授：浙江大学求是讲席教授，研究领域包括人工智能、计算机视觉、多媒体大数据分析等。

  - 肖俊教授：浙江大学教授，研究方向涵盖视觉内容分析与理解，包括视觉注意力机制、图像描述、视觉问答等。

 

 

 >AI:多模态交互，开创新领域。 

原文链接:[https://venturebeat.com/security/how-generative-ai-is-defining-the-future-of-identity-access-management/](https://venturebeat.com/security/how-generative-ai-is-defining-the-future-of-identity-access-management/)

### 【ChatGPT】入门指南 

>要点解析:

 1. **ChatGPT简介:** ChatGPT是基于GPT-3.5架构的大型语言模型，旨在提供智能的对话和问答服务。通过深度学习技术，它能够生成合理的响应，处理语言任务如对话、问答等。

 2. **使用流程:** 用户可以在ChatGPT官方网站登录账号，选择模式（文本生成、对话生成、问答生成），然后输入问题或对话，ChatGPT即时生成文字响应。

 3. **ChatGPT的三种模式:** 

  - **文本生成模式:** 用于生成具有一定主题和风格的文章、段落和句子，适用于新闻报道、创意写作等。

  - **对话生成模式:** 模拟人类之间的对话，可用于语言表达和对话技巧的练习，适用于虚拟客服、智能机器人等。

  - **问答生成模式:** 回答用户问题，提供准确实用的答案，适用于智能客服、搜索引擎等。

 4. **如何正确启动ChatGPT:** 用户登录ChatGPT官方网站，选择模式，输入问题，注意设置语言为中文简体，确保获得中文回答。

 5. **选择正确的模式:** 用户需确定需求和目标，了解模式特点和应用场景，考虑输出结果和表现，选择最适合的ChatGPT模式。

 

 

 >AI:ChatGPT助力智能对话，革新人机交互。 

原文链接:[https://juejin.cn/post/7300592516759158835](https://juejin.cn/post/7300592516759158835)

